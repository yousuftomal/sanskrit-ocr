# -*- coding: utf-8 -*-
"""Sanskrit_OCR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17NaRgp9pkDxatVsVFTINLBlN08ReTFNf


**Sanskrit OCR using CV2 and CNN.**
"""

import numpy as np
import cv2
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dropout
import pickle

# Load the dataset
with open("dev_letter_D.p", "rb") as file:
    dataset = pickle.load(file, encoding='latin1')

print("Number of letter images in the dataset are: " + str(len(dataset)))  # Fixed variable name 'db' to 'dataset'

# Separate the data into images and labels
images = [entry[0] for entry in dataset]
labels = [entry[1] for entry in dataset]

# Preprocess the images
# Resize and normalize the images, and convert to grayscale
images = [cv2.resize(image, (32, 32)) for image in images]
images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in images]
images = np.array(images, dtype=np.float32) / 255.0  # Normalize to the range [0, 1]

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

# Convert your data to NumPy arrays and one-hot encode the labels
X_train = np.array(X_train).reshape(-1, 32, 32, 1)  # Reshape for CNN
X_test = np.array(X_test).reshape(-1, 32, 32, 1)
y_train = to_categorical(y_train, num_classes=602)  # Assuming 602 classes
y_test = to_categorical(y_test, num_classes=602)  # Assuming 602 classes

# Define a simple convolutional neural network (CNN) model
model = keras.Sequential([
    layers.Input(shape=(32, 32, 1)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(602, activation='softmax')  # 602 classes for Sanskrit characters
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Changed loss to 'categorical_crossentropy'

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

#Save the model
model.save("sanskrit_letters.model")

#Download the model folder as .zip
!zip -r /content/sanskrit_letters.zip /content/sanskrit_letters.model

# Evaluate the model
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_accuracy}")

# Use the model for character recognition
# You can use the model to predict the class of a character in a new image
# For example:
sample_image = cv2.imread("12.png")
sample_image = cv2.resize(sample_image, (32, 32))
sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2GRAY)
sample_image = np.array(sample_image) / 255.0
prediction = model.predict(np.expand_dims(sample_image, axis=0))
predicted_class = np.argmax(prediction)

# Print the English class annotation for the predicted class
print(f"Predicted class: {predicted_class} - {dataset[predicted_class][2]}")